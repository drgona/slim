

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Linear &mdash; SLiM 0.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/slim.ico"/>
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="RNN" href="rnn.html" />
    <link rel="prev" title="SLiM: Structured Linear Maps" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> SLiM
          

          
            
            <img src="_static/slim.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Docs:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Linear</a></li>
<li class="toctree-l1"><a class="reference internal" href="rnn.html">RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks.html">Benchmarks</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SLiM</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Linear</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/linear.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-linear">
<span id="linear"></span><h1>Linear<a class="headerlink" href="#module-linear" title="Permalink to this headline">¶</a></h1>
<p>Structured linear maps which are drop in replacements for torch.nn.Linear</p>
<div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<ul>
<li><p>Generalize to batch matrix multiplication for arbitrary N-dimensional tensors</p></li>
<li><p>Additional linear parametrizations:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>Strictly diagonally dominant matrix is non-singular:</dt><dd><ul>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Diagonally_dominant_matrix">https://en.wikipedia.org/wiki/Diagonally_dominant_matrix</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Doubly stochastic matrix:</dt><dd><ul>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Doubly_stochastic_matrix">https://en.wikipedia.org/wiki/Doubly_stochastic_matrix</a></p></li>
<li><p><a class="reference external" href="https://github.com/btaba/sinkhorn_knopp">https://github.com/btaba/sinkhorn_knopp</a></p></li>
<li><p><a class="reference external" href="https://github.com/HeddaCohenIndelman/Learning-Gumbel-Sinkhorn-Permutations-w-Pytorch">https://github.com/HeddaCohenIndelman/Learning-Gumbel-Sinkhorn-Permutations-w-Pytorch</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Hamiltonian matrix:</dt><dd><ul>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Hamiltonian_matrix">https://en.wikipedia.org/wiki/Hamiltonian_matrix</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Regular split: <span class="math notranslate nohighlight">\(A = B − C\)</span> is a regular splitting of <span class="math notranslate nohighlight">\(A\)</span> if <span class="math notranslate nohighlight">\(B^{−1} ≥ 0\)</span> and <span class="math notranslate nohighlight">\(C ≥ 0\)</span>:</dt><dd><ul>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_splitting">https://en.wikipedia.org/wiki/Matrix_splitting</a></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<p>Pytorch weight initializations used in this module:</p>
<ul class="simple">
<li><p>torch.nn.init.xavier_normal_(tensor, gain=1.0)</p></li>
<li><p>torch.nn.init.kaiming_normal_(tensor, a=0, mode=’fan_in’, nonlinearity=’leaky_relu’)</p></li>
<li><p>torch.nn.init.orthogonal_(tensor, gain=1)</p></li>
<li><p>torch.nn.init.sparse_(tensor, sparsity, std=0.01)</p></li>
</ul>
<dl class="py class">
<dt id="linear.ButterflyLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">ButterflyLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">complex</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">tied_weight</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">increasing_stride</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">ortho_init</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#ButterflyLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.ButterflyLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Sparse structured linear maps from: <a class="reference external" href="https://github.com/HazyResearch/learning-circuits">https://github.com/HazyResearch/learning-circuits</a></p>
<dl class="py method">
<dt id="linear.ButterflyLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#ButterflyLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.ButterflyLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.ButterflyLinear.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#ButterflyLinear.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.ButterflyLinear.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – (torch.Tensor, shape=[batchsize, in_features])</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(torch.Tensor, shape=[batchsize, out_features])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.ButterflyLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.ButterflyLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.DampedSkewSymmetricLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">DampedSkewSymmetricLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#DampedSkewSymmetricLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.DampedSkewSymmetricLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Skew-symmetric linear map with damping.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Skew-symmetric_matrix">https://en.wikipedia.org/wiki/Skew-symmetric_matrix</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.DampedSkewSymmetricLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#DampedSkewSymmetricLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.DampedSkewSymmetricLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.DampedSkewSymmetricLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.DampedSkewSymmetricLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.GershgorinLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">GershgorinLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">real</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#GershgorinLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.GershgorinLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses Gershgorin Disc parametrization to constrain eigenvalues of the matrix. See:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2011.13492">https://arxiv.org/abs/2011.13492</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.GershgorinLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#GershgorinLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.GershgorinLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.GershgorinLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.GershgorinLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="linear.Hprod">
<code class="sig-prename descclassname">linear.</code><code class="sig-name descname">Hprod</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">u</span></em>, <em class="sig-param"><span class="n">k</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#Hprod"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.Hprod" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function for computing matrix multiply via householder reflection representation.
:param x: (torch.Tensor shape=[batchsize, dimension])
:param u: (torch.Tensor shape=[dimension])
:param k: (int)
:return: (torch.Tensor shape=[batchsize, dimension])</p>
</dd></dl>

<dl class="py class">
<dt id="linear.IdentityGradReLU">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">IdentityGradReLU</code><a class="reference internal" href="_modules/linear.html#IdentityGradReLU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.IdentityGradReLU" title="Permalink to this definition">¶</a></dt>
<dd><p>We can implement our own custom autograd Functions by subclassing
torch.autograd.Function and implementing the forward and backward passes
which operate on Tensors.</p>
<dl class="py method">
<dt id="linear.IdentityGradReLU.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ctx</span></em>, <em class="sig-param"><span class="n">grad_output</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#IdentityGradReLU.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.IdentityGradReLU.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>In the backward pass we receive a Tensor containing the gradient of the loss
with respect to the output, and we need to compute the gradient of the loss
with respect to the input. Here we are just passing through the previous gradient since we want
the gradient for this max operation to be gradient of identity.</p>
</dd></dl>

<dl class="py method">
<dt id="linear.IdentityGradReLU.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ctx</span></em>, <em class="sig-param"><span class="n">input</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#IdentityGradReLU.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.IdentityGradReLU.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>In the forward pass we receive a Tensor containing the input and return
a Tensor containing the output. ctx is a context object that can be used
to stash information for backward computation. You can cache arbitrary
objects for use in the backward pass using the ctx.save_for_backward method.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.IdentityInitLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">IdentityInitLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#IdentityInitLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.IdentityInitLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Linear map initialized to Identity matrix.</p>
<dl class="py attribute">
<dt id="linear.IdentityInitLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.IdentityInitLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.IdentityLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">IdentityLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#IdentityLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.IdentityLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Identity operation compatible with all LinearBase functionality.</p>
<dl class="py attribute">
<dt id="linear.IdentityLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.IdentityLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.L0Linear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">L0Linear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">weight_decay</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">droprate_init</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">temperature</span><span class="o">=</span><span class="default_value">0.6666666666666666</span></em>, <em class="sig-param"><span class="n">lamba</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#L0Linear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.L0Linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of L0 regularization for the input units of a fully connected layer</p>
<ul class="simple">
<li><p>Reference implementation: <a class="reference external" href="https://github.com/AMLab-Amsterdam/L0_regularization/blob/master/l0_layers.py">https://github.com/AMLab-Amsterdam/L0_regularization/blob/master/l0_layers.py</a></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1712.01312.pdf">https://arxiv.org/pdf/1712.01312.pdf</a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This implementation may need to be adjusted as there is the same sampling for each input
in the minibatch which may inhibit convergence. Also, there will be a different sampling
for each call during training so it may cause issues included in a layer for a recurrent
computation (fx in state space model).</p>
</div>
<dl class="py method">
<dt id="linear.L0Linear.cdf_qz">
<code class="sig-name descname">cdf_qz</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#L0Linear.cdf_qz"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.L0Linear.cdf_qz" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements the CDF of the ‘stretched’ concrete distribution</p>
</dd></dl>

<dl class="py method">
<dt id="linear.L0Linear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#L0Linear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.L0Linear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.L0Linear.get_eps">
<code class="sig-name descname">get_eps</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">size</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#L0Linear.get_eps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.L0Linear.get_eps" title="Permalink to this definition">¶</a></dt>
<dd><p>Uniform random numbers for the concrete distribution</p>
</dd></dl>

<dl class="py method">
<dt id="linear.L0Linear.quantile_concrete">
<code class="sig-name descname">quantile_concrete</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#L0Linear.quantile_concrete"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.L0Linear.quantile_concrete" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements the quantile, aka inverse CDF, of the ‘stretched’ concrete distribution</p>
</dd></dl>

<dl class="py method">
<dt id="linear.L0Linear.reg_error">
<code class="sig-name descname">reg_error</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#L0Linear.reg_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.L0Linear.reg_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Expected L0 norm under the stochastic gates, takes into account and re-weights also a potential L2 penalty</p>
</dd></dl>

<dl class="py attribute">
<dt id="linear.L0Linear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.L0Linear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.LassoLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">LassoLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">gamma</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LassoLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LassoLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>From <a class="reference external" href="https://leon.bottou.org/publications/pdf/compstat-2010.pdf">https://leon.bottou.org/publications/pdf/compstat-2010.pdf</a></p>
<dl class="py method">
<dt id="linear.LassoLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LassoLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LassoLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.LassoLinear.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LassoLinear.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LassoLinear.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – (torch.Tensor, shape=[batchsize, in_features])</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(torch.Tensor, shape=[batchsize, out_features])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.LassoLinear.reg_error">
<code class="sig-name descname">reg_error</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LassoLinear.reg_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LassoLinear.reg_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Regularization error associated with linear map parametrization.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.LassoLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.LassoLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.LassoLinearRELU">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">LassoLinearRELU</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">gamma</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LassoLinearRELU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LassoLinearRELU" title="Permalink to this definition">¶</a></dt>
<dd><p>From <a class="reference external" href="https://leon.bottou.org/publications/pdf/compstat-2010.pdf">https://leon.bottou.org/publications/pdf/compstat-2010.pdf</a></p>
<dl class="py method">
<dt id="linear.LassoLinearRELU.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LassoLinearRELU.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LassoLinearRELU.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.LassoLinearRELU.reg_error">
<code class="sig-name descname">reg_error</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LassoLinearRELU.reg_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LassoLinearRELU.reg_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Regularization error associated with linear map parametrization.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.LassoLinearRELU.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.LassoLinearRELU.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.LeftStochasticLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">LeftStochasticLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LeftStochasticLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LeftStochasticLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>A left stochastic matrix is a real square matrix, with each column summing to 1.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_matrix">https://en.wikipedia.org/wiki/Stochastic_matrix</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.LeftStochasticLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LeftStochasticLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LeftStochasticLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.LeftStochasticLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.LeftStochasticLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.Linear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">Linear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#Linear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.Linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for torch.nn.Linear with additional slim methods returning matrix,
eigenvectors, eigenvalues and regularization error.</p>
<dl class="py method">
<dt id="linear.Linear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#Linear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.Linear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.Linear.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#Linear.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.Linear.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – (torch.Tensor, shape=[batchsize, in_features])</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(torch.Tensor, shape=[batchsize, out_features])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.Linear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.Linear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.LinearBase">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">LinearBase</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LinearBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LinearBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class defining linear map interface.</p>
<dl class="py method">
<dt id="linear.LinearBase.effective_W">
<em class="property">abstract </em><code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LinearBase.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LinearBase.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.LinearBase.eig">
<code class="sig-name descname">eig</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">eigenvectors</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LinearBase.eig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LinearBase.eig" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the eigenvalues (optionally eigenvectors) of the linear map used in matrix multiplication.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>eigenvectors</strong> – (bool) Whether to return eigenvectors along with eigenvalues.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(torch.Tensor) Vector of eigenvalues, optionally a tuple including a matrix of eigenvectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.LinearBase.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LinearBase.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LinearBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – (torch.Tensor, shape=[batchsize, in_features])</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(torch.Tensor, shape=[batchsize, out_features])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.LinearBase.reg_error">
<code class="sig-name descname">reg_error</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#LinearBase.reg_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.LinearBase.reg_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Regularization error associated with linear map parametrization.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.LinearBase.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.LinearBase.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.NonNegativeLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">NonNegativeLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#NonNegativeLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.NonNegativeLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Positive parametrization of linear map via Relu.</p>
<dl class="py method">
<dt id="linear.NonNegativeLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#NonNegativeLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.NonNegativeLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.NonNegativeLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.NonNegativeLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.OrthogonalLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">OrthogonalLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#OrthogonalLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.OrthogonalLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Orthogonal parametrization via householder reflection</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1612.00188">https://arxiv.org/abs/1612.00188</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.OrthogonalLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#OrthogonalLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.OrthogonalLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.OrthogonalLinear.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#OrthogonalLinear.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.OrthogonalLinear.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – (torch.Tensor, shape=[batchsize, in_features])</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(torch.Tensor, shape=[batchsize, out_features])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.OrthogonalLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.OrthogonalLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.PSDLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">PSDLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#PSDLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.PSDLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Symmetric Positive semi-definite matrix.</p>
<dl class="py method">
<dt id="linear.PSDLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#PSDLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.PSDLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.PSDLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.PSDLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.PerronFrobeniusLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">PerronFrobeniusLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#PerronFrobeniusLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.PerronFrobeniusLinear" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt id="linear.PerronFrobeniusLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#PerronFrobeniusLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.PerronFrobeniusLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.PerronFrobeniusLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.PerronFrobeniusLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.RightStochasticLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">RightStochasticLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#RightStochasticLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.RightStochasticLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>A right stochastic matrix is a real square matrix, with each row summing to 1.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_matrix">https://en.wikipedia.org/wiki/Stochastic_matrix</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.RightStochasticLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#RightStochasticLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.RightStochasticLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.RightStochasticLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.RightStochasticLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SVDLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SVDLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SVDLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SVDLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Linear map with constrained eigenvalues via approximate SVD factorization.
Soft SVD based regularization of matrix <span class="math notranslate nohighlight">\(A\)</span>.
<span class="math notranslate nohighlight">\(A = U \Sigma V\)</span>.
<span class="math notranslate nohighlight">\(U,V\)</span> are unitary matrices (orthogonal for real matrices <span class="math notranslate nohighlight">\(A\)</span>).
<span class="math notranslate nohighlight">\(\Sigma\)</span> is a diagonal matrix of singular values (square roots of eigenvalues).</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2101.01864">https://arxiv.org/abs/2101.01864</a></p></li>
</ul>
<p>This below paper uses the same factorization and orthogonality constraint as implemented here
but enforces a low rank prior on the map by introducing a sparse prior on the singular values:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w40/Yang_Learning_Low-Rank_Deep_Neural_Networks_via_Singular_Vector_Orthogonality_Regularization_CVPRW_2020_paper.pdf">https://openaccess.thecvf.com/content_CVPRW_2020/papers/w40/Yang_Learning_Low-Rank_Deep_Neural_Networks_via_Singular_Vector_Orthogonality_Regularization_CVPRW_2020_paper.pdf</a></p></li>
</ul>
<p>Also a similar regularization on the factors as to our implementation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pdfs.semanticscholar.org/78b2/9eba4d6c836483c0aa67d637205e95223ae4.pdf">https://pdfs.semanticscholar.org/78b2/9eba4d6c836483c0aa67d637205e95223ae4.pdf</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.SVDLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SVDLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SVDLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Matrix for linear transformation with dominant eigenvalue between sigma_max and sigma_min</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.SVDLinear.orthogonal_error">
<code class="sig-name descname">orthogonal_error</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">weight</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SVDLinear.orthogonal_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SVDLinear.orthogonal_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="linear.SVDLinear.reg_error">
<code class="sig-name descname">reg_error</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SVDLinear.reg_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SVDLinear.reg_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Regularization error enforces orthogonality constraint for matrix factors</p>
</dd></dl>

<dl class="py attribute">
<dt id="linear.SVDLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SVDLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SVDLinearLearnBounds">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SVDLinearLearnBounds</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SVDLinearLearnBounds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SVDLinearLearnBounds" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py attribute">
<dt id="linear.SVDLinearLearnBounds.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SVDLinearLearnBounds.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SchurDecompositionLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SchurDecompositionLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">l2</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SchurDecompositionLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SchurDecompositionLinear" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p><a class="reference external" href="https://papers.nips.cc/paper/9513-non-normal-recurrent-neural-network-nnrnn-learning-long-time-dependencies-while-improving-expressivity-with-transient-dynamics.pdf">https://papers.nips.cc/paper/9513-non-normal-recurrent-neural-network-nnrnn-learning-long-time-dependencies-while-improving-expressivity-with-transient-dynamics.pdf</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.SchurDecompositionLinear.build_T">
<code class="sig-name descname">build_T</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">T</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SchurDecompositionLinear.build_T"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SchurDecompositionLinear.build_T" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="linear.SchurDecompositionLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SchurDecompositionLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SchurDecompositionLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.SchurDecompositionLinear.reg_error">
<code class="sig-name descname">reg_error</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SchurDecompositionLinear.reg_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SchurDecompositionLinear.reg_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Regularization error associated with linear map parametrization.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.SchurDecompositionLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SchurDecompositionLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SkewSymmetricLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SkewSymmetricLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SkewSymmetricLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SkewSymmetricLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Skew-symmetric (or antisymmetric) matrix <span class="math notranslate nohighlight">\(A\)</span> (effective_W) is a square matrix whose transpose equals its negative.
<span class="math notranslate nohighlight">\(A = -A^T\)</span></p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Skew-symmetric_matrix">https://en.wikipedia.org/wiki/Skew-symmetric_matrix</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.SkewSymmetricLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SkewSymmetricLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SkewSymmetricLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.SkewSymmetricLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SkewSymmetricLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SpectralLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SpectralLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">n_U_reflectors</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_V_reflectors</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SpectralLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SpectralLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>SVD paramaterized linear map of form <span class="math notranslate nohighlight">\(U \Sigma V\)</span> via Householder reflection.
Singular values can be constrained to a range.
Translated from tensorflow code:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/zhangjiong724/spectral-RNN/blob/master/code/spectral_rnn.py">https://github.com/zhangjiong724/spectral-RNN/blob/master/code/spectral_rnn.py</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.SpectralLinear.Sigma">
<code class="sig-name descname">Sigma</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SpectralLinear.Sigma"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SpectralLinear.Sigma" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="linear.SpectralLinear.Umultiply">
<code class="sig-name descname">Umultiply</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SpectralLinear.Umultiply"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SpectralLinear.Umultiply" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="linear.SpectralLinear.Vmultiply">
<code class="sig-name descname">Vmultiply</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SpectralLinear.Vmultiply"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SpectralLinear.Vmultiply" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="linear.SpectralLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SpectralLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SpectralLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="linear.SpectralLinear.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SpectralLinear.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SpectralLinear.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – (torch.Tensor, shape=[batchsize, in_features])</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(torch.Tensor, shape=[batchsize, out_features])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.SpectralLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SpectralLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SplitLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SplitLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SplitLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SplitLinear" title="Permalink to this definition">¶</a></dt>
<dd><p><span class="math notranslate nohighlight">\(A = B − C\)</span>, with <span class="math notranslate nohighlight">\(B ≥ 0\)</span> and <span class="math notranslate nohighlight">\(C ≥ 0\)</span>.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_splitting">https://en.wikipedia.org/wiki/Matrix_splitting</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.SplitLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SplitLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SplitLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.SplitLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SplitLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SquareLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SquareLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SquareLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SquareLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for linear map parametrizations that assume a square matrix.</p>
<dl class="py method">
<dt id="linear.SquareLinear.effective_W">
<em class="property">abstract </em><code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SquareLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SquareLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.SquareLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SquareLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.StableSplitLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">StableSplitLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#StableSplitLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.StableSplitLinear" title="Permalink to this definition">¶</a></dt>
<dd><p><span class="math notranslate nohighlight">\(A = B − C\)</span>, with stable <cite>B</cite> and stable <cite>C</cite></p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_splitting">https://en.wikipedia.org/wiki/Matrix_splitting</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.StableSplitLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#StableSplitLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.StableSplitLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.StableSplitLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.StableSplitLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SymmetricLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SymmetricLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SymmetricLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SymmetricLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Symmetric matrix <span class="math notranslate nohighlight">\(A\)</span> (effective_W) is a square matrix that is equal to its transpose. <span class="math notranslate nohighlight">\(A = A^T\)</span></p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Symmetric_matrix">https://en.wikipedia.org/wiki/Symmetric_matrix</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.SymmetricLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SymmetricLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SymmetricLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.SymmetricLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SymmetricLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SymmetricSVDLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SymmetricSVDLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SymmetricSVDLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SymmetricSVDLinear" title="Permalink to this definition">¶</a></dt>
<dd><p><span class="math notranslate nohighlight">\(U = V\)</span></p>
<dl class="py attribute">
<dt id="linear.SymmetricSVDLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SymmetricSVDLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SymmetricSpectralLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SymmetricSpectralLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">n_reflectors</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sigma_min</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">sigma_max</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SymmetricSpectralLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SymmetricSpectralLinear" title="Permalink to this definition">¶</a></dt>
<dd><p><span class="math notranslate nohighlight">\(U = V\)</span></p>
<dl class="py attribute">
<dt id="linear.SymmetricSpectralLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SymmetricSpectralLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="linear.SymplecticLinear">
<em class="property">class </em><code class="sig-prename descclassname">linear.</code><code class="sig-name descname">SymplecticLinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">insize</span></em>, <em class="sig-param"><span class="n">outsize</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SymplecticLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SymplecticLinear" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Symplectic_matrix">https://en.wikipedia.org/wiki/Symplectic_matrix</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1705.03341">https://arxiv.org/abs/1705.03341</a></p></li>
</ul>
<dl class="py method">
<dt id="linear.SymplecticLinear.effective_W">
<code class="sig-name descname">effective_W</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/linear.html#SymplecticLinear.effective_W"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#linear.SymplecticLinear.effective_W" title="Permalink to this definition">¶</a></dt>
<dd><p>The matrix used in the equivalent matrix multiplication for the parametrization</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(torch.Tensor, shape=[insize, outsize]) Matrix used in matrix multiply</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="linear.SymplecticLinear.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#linear.SymplecticLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="rnn.html" class="btn btn-neutral float-right" title="RNN" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="SLiM: Structured Linear Maps" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Aaron Tuor, Jan Drgona, Elliott Skomski, Soumya Vasisht

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>